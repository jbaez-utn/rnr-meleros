{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos usando tensorflow: Muestras por segundo\n",
    "\n",
    "Recopilacion de modelos implementados principalmente usando tensorflow. \n",
    "\n",
    "Imports y herramientas usadas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
    "rcParams['figure.figsize'] = 14, 8 \n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procedemos entontes a la carga y preprocesado de datos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_por_segundo = \"../data/individual/resumen-comportamientos_Matilda_dataset_per_second.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comenzamos analizando los datos de entrada. Revisamos el tama√±o, la forma y las columnas que tiene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw = pd.read_csv(datos_por_segundo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN values: 0\n"
     ]
    }
   ],
   "source": [
    "# Do we have NaN values in data_raw?\n",
    "print(f\"NaN values: {data_raw.isna().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_0</th>\n",
       "      <th>y_0</th>\n",
       "      <th>z_0</th>\n",
       "      <th>ODBA_0</th>\n",
       "      <th>x_1</th>\n",
       "      <th>y_1</th>\n",
       "      <th>z_1</th>\n",
       "      <th>ODBA_1</th>\n",
       "      <th>x_2</th>\n",
       "      <th>y_2</th>\n",
       "      <th>...</th>\n",
       "      <th>z_7</th>\n",
       "      <th>ODBA_7</th>\n",
       "      <th>x_8</th>\n",
       "      <th>y_8</th>\n",
       "      <th>z_8</th>\n",
       "      <th>ODBA_8</th>\n",
       "      <th>x_9</th>\n",
       "      <th>y_9</th>\n",
       "      <th>z_9</th>\n",
       "      <th>ODBA_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1240.000000</td>\n",
       "      <td>1240.000000</td>\n",
       "      <td>1240.000000</td>\n",
       "      <td>1240.000000</td>\n",
       "      <td>1240.000000</td>\n",
       "      <td>1240.000000</td>\n",
       "      <td>1240.000000</td>\n",
       "      <td>1240.000000</td>\n",
       "      <td>1240.000000</td>\n",
       "      <td>1240.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1240.000000</td>\n",
       "      <td>1240.000000</td>\n",
       "      <td>1240.000000</td>\n",
       "      <td>1240.000000</td>\n",
       "      <td>1240.000000</td>\n",
       "      <td>1240.000000</td>\n",
       "      <td>1240.000000</td>\n",
       "      <td>1240.000000</td>\n",
       "      <td>1240.000000</td>\n",
       "      <td>1240.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.215241</td>\n",
       "      <td>0.116638</td>\n",
       "      <td>0.758530</td>\n",
       "      <td>0.298850</td>\n",
       "      <td>0.214296</td>\n",
       "      <td>0.113839</td>\n",
       "      <td>0.752203</td>\n",
       "      <td>0.295632</td>\n",
       "      <td>0.213589</td>\n",
       "      <td>0.117898</td>\n",
       "      <td>...</td>\n",
       "      <td>0.754686</td>\n",
       "      <td>0.303678</td>\n",
       "      <td>0.210933</td>\n",
       "      <td>0.117080</td>\n",
       "      <td>0.757042</td>\n",
       "      <td>0.296563</td>\n",
       "      <td>0.210920</td>\n",
       "      <td>0.122132</td>\n",
       "      <td>0.755353</td>\n",
       "      <td>0.304522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.374927</td>\n",
       "      <td>0.263871</td>\n",
       "      <td>0.297255</td>\n",
       "      <td>0.254621</td>\n",
       "      <td>0.380278</td>\n",
       "      <td>0.266080</td>\n",
       "      <td>0.321738</td>\n",
       "      <td>0.329812</td>\n",
       "      <td>0.377200</td>\n",
       "      <td>0.266825</td>\n",
       "      <td>...</td>\n",
       "      <td>0.297195</td>\n",
       "      <td>0.264788</td>\n",
       "      <td>0.378386</td>\n",
       "      <td>0.261031</td>\n",
       "      <td>0.300800</td>\n",
       "      <td>0.267159</td>\n",
       "      <td>0.377138</td>\n",
       "      <td>0.264529</td>\n",
       "      <td>0.295316</td>\n",
       "      <td>0.279301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.015600</td>\n",
       "      <td>-0.890600</td>\n",
       "      <td>-0.375000</td>\n",
       "      <td>0.007790</td>\n",
       "      <td>-1.046900</td>\n",
       "      <td>-1.265600</td>\n",
       "      <td>-3.906300</td>\n",
       "      <td>0.004187</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.953100</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.453100</td>\n",
       "      <td>0.003690</td>\n",
       "      <td>-1.546900</td>\n",
       "      <td>-0.984400</td>\n",
       "      <td>-0.421900</td>\n",
       "      <td>0.007767</td>\n",
       "      <td>-1.234400</td>\n",
       "      <td>-0.968800</td>\n",
       "      <td>-0.406300</td>\n",
       "      <td>0.004140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.015600</td>\n",
       "      <td>-0.046900</td>\n",
       "      <td>0.656300</td>\n",
       "      <td>0.101486</td>\n",
       "      <td>0.015600</td>\n",
       "      <td>-0.046900</td>\n",
       "      <td>0.656300</td>\n",
       "      <td>0.099504</td>\n",
       "      <td>0.015600</td>\n",
       "      <td>-0.046900</td>\n",
       "      <td>...</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.104721</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.031300</td>\n",
       "      <td>0.656300</td>\n",
       "      <td>0.097410</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.031300</td>\n",
       "      <td>0.640600</td>\n",
       "      <td>0.101443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.140600</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.236155</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.140600</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.223923</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.140600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.237535</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.226552</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.140600</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.230173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.359400</td>\n",
       "      <td>0.281300</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.419188</td>\n",
       "      <td>0.359400</td>\n",
       "      <td>0.296900</td>\n",
       "      <td>0.921900</td>\n",
       "      <td>0.409158</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.296900</td>\n",
       "      <td>...</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.419957</td>\n",
       "      <td>0.359400</td>\n",
       "      <td>0.296900</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.397898</td>\n",
       "      <td>0.347700</td>\n",
       "      <td>0.296900</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.412864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.031300</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>1.343800</td>\n",
       "      <td>2.029297</td>\n",
       "      <td>2.328100</td>\n",
       "      <td>1.125000</td>\n",
       "      <td>1.468800</td>\n",
       "      <td>7.951573</td>\n",
       "      <td>1.234400</td>\n",
       "      <td>0.968800</td>\n",
       "      <td>...</td>\n",
       "      <td>1.406300</td>\n",
       "      <td>1.908370</td>\n",
       "      <td>1.062500</td>\n",
       "      <td>1.031300</td>\n",
       "      <td>1.390600</td>\n",
       "      <td>1.986470</td>\n",
       "      <td>1.046900</td>\n",
       "      <td>1.125000</td>\n",
       "      <td>1.406300</td>\n",
       "      <td>2.283370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows √ó 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               x_0          y_0          z_0       ODBA_0          x_1  \\\n",
       "count  1240.000000  1240.000000  1240.000000  1240.000000  1240.000000   \n",
       "mean      0.215241     0.116638     0.758530     0.298850     0.214296   \n",
       "std       0.374927     0.263871     0.297255     0.254621     0.380278   \n",
       "min      -1.015600    -0.890600    -0.375000     0.007790    -1.046900   \n",
       "25%       0.015600    -0.046900     0.656300     0.101486     0.015600   \n",
       "50%       0.125000     0.140600     0.875000     0.236155     0.125000   \n",
       "75%       0.359400     0.281300     0.937500     0.419188     0.359400   \n",
       "max       1.031300     1.250000     1.343800     2.029297     2.328100   \n",
       "\n",
       "               y_1          z_1       ODBA_1          x_2          y_2  ...  \\\n",
       "count  1240.000000  1240.000000  1240.000000  1240.000000  1240.000000  ...   \n",
       "mean      0.113839     0.752203     0.295632     0.213589     0.117898  ...   \n",
       "std       0.266080     0.321738     0.329812     0.377200     0.266825  ...   \n",
       "min      -1.265600    -3.906300     0.004187    -1.000000    -0.953100  ...   \n",
       "25%      -0.046900     0.656300     0.099504     0.015600    -0.046900  ...   \n",
       "50%       0.140600     0.875000     0.223923     0.125000     0.140600  ...   \n",
       "75%       0.296900     0.921900     0.409158     0.375000     0.296900  ...   \n",
       "max       1.125000     1.468800     7.951573     1.234400     0.968800  ...   \n",
       "\n",
       "               z_7       ODBA_7          x_8          y_8          z_8  \\\n",
       "count  1240.000000  1240.000000  1240.000000  1240.000000  1240.000000   \n",
       "mean      0.754686     0.303678     0.210933     0.117080     0.757042   \n",
       "std       0.297195     0.264788     0.378386     0.261031     0.300800   \n",
       "min      -0.453100     0.003690    -1.546900    -0.984400    -0.421900   \n",
       "25%       0.625000     0.104721     0.000000    -0.031300     0.656300   \n",
       "50%       0.875000     0.237535     0.125000     0.125000     0.875000   \n",
       "75%       0.937500     0.419957     0.359400     0.296900     0.937500   \n",
       "max       1.406300     1.908370     1.062500     1.031300     1.390600   \n",
       "\n",
       "            ODBA_8          x_9          y_9          z_9       ODBA_9  \n",
       "count  1240.000000  1240.000000  1240.000000  1240.000000  1240.000000  \n",
       "mean      0.296563     0.210920     0.122132     0.755353     0.304522  \n",
       "std       0.267159     0.377138     0.264529     0.295316     0.279301  \n",
       "min       0.007767    -1.234400    -0.968800    -0.406300     0.004140  \n",
       "25%       0.097410     0.000000    -0.031300     0.640600     0.101443  \n",
       "50%       0.226552     0.125000     0.140600     0.875000     0.230173  \n",
       "75%       0.397898     0.347700     0.296900     0.937500     0.412864  \n",
       "max       1.986470     1.046900     1.125000     1.406300     2.283370  \n",
       "\n",
       "[8 rows x 40 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_raw.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1240, 41)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['x_0', 'y_0', 'z_0', 'ODBA_0', 'x_1', 'y_1', 'z_1', 'ODBA_1', 'x_2',\n",
       "       'y_2', 'z_2', 'ODBA_2', 'x_3', 'y_3', 'z_3', 'ODBA_3', 'x_4', 'y_4',\n",
       "       'z_4', 'ODBA_4', 'x_5', 'y_5', 'z_5', 'ODBA_5', 'x_6', 'y_6', 'z_6',\n",
       "       'ODBA_6', 'x_7', 'y_7', 'z_7', 'ODBA_7', 'x_8', 'y_8', 'z_8', 'ODBA_8',\n",
       "       'x_9', 'y_9', 'z_9', 'ODBA_9', 'Comportamiento'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_raw.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Analisis de datos\n",
    "El primer paso es analizar los datos disponibles. En este caso, usamos seaborn para graficar la cantidad de muestras que tenemos por cada tipo de comportamiento en el dataset seleccionado. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Comportamiento de Matilda')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = sns.countplot(x='Comportamiento', data=data_raw)\n",
    "f.set_title('Comportamiento de Matilda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removemos los outliers, valores de ODBA fuera de rangos logicos generales. Vamos a considerar 3 desviaciones estandar, lo que se llama numero de z-scores. Esto es porque los valores fuera de 3 desviaciones estandard de la media no tienen mucha logica de ser. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12400,)\n",
      "[0.83021 1.28341 1.12711 1.17411 1.29901 0.83021 0.90831 0.65841 0.55527\n",
      " 0.39261]\n",
      "NaN values: 0\n",
      "Mean: 0.2944537333333333\n",
      "Standard deviation: 0.2669794553346632\n",
      "      x_0     y_0     z_0    ODBA_0     x_1     y_1     z_1    ODBA_1     x_2  \\\n",
      "0  0.0781  0.0781  0.9375  0.830210 -0.1563  0.2031  1.0313  1.283410 -0.0625   \n",
      "1 -0.0625 -0.1406  1.0000  0.237990  0.0313  0.0469  0.7031  0.450650  0.0469   \n",
      "2 -0.0469  0.3906  0.8281  0.591150 -0.1094  0.3438  0.9688  0.465190 -0.0625   \n",
      "3 -0.1875 -0.1250  0.9375  0.174450 -0.1875 -0.0938  0.9531  0.158850 -0.1563   \n",
      "4 -0.2500 -0.0313  0.9688  0.225593 -0.2656 -0.0469  0.8750  0.234887 -0.2500   \n",
      "\n",
      "      y_2  ...  ODBA_0_zscore  ODBA_1_zscore  ODBA_2_zscore  ODBA_3_zscore  \\\n",
      "0  0.2344  ...       2.006732       3.704241       3.118803       3.294846   \n",
      "1  0.3125  ...      -0.211491       0.585050       1.341812       0.467438   \n",
      "2  0.1719  ...       1.111307       0.639511       0.112504      -0.706960   \n",
      "3 -0.1250  ...      -0.449487      -0.507918      -0.449112      -0.449112   \n",
      "4 -0.0469  ...      -0.257924      -0.223115      -0.339978      -0.316730   \n",
      "\n",
      "   ODBA_4_zscore  ODBA_5_zscore  ODBA_6_zscore  ODBA_7_zscore  ODBA_8_zscore  \\\n",
      "0       3.762673       2.006732       2.299264       1.363237       0.976915   \n",
      "1      -0.211491       0.728881       1.076249       0.670450       0.467438   \n",
      "2      -0.035747       0.198728       0.315216      -0.156580      -0.328279   \n",
      "3      -0.387085      -0.273818      -0.562379      -0.535261      -0.297190   \n",
      "4      -0.199867      -0.258299      -0.316730      -0.258299      -0.433593   \n",
      "\n",
      "   ODBA_9_zscore  \n",
      "0       0.367655  \n",
      "1       0.346230  \n",
      "2      -0.098149  \n",
      "3      -0.418024  \n",
      "4      -0.516021  \n",
      "\n",
      "[5 rows x 51 columns]\n",
      "Original data shape: (1240, 41)\n",
      "Data without outliers filtered by ODBA value: (1171, 41)\n"
     ]
    }
   ],
   "source": [
    "# Create new dataframe to calculate outliers\n",
    "data_outlier_calc = data_raw.copy()\n",
    "\n",
    "# Create new numpy array from ODBA columns\n",
    "aux_combined_data = data_outlier_calc[['ODBA_0', 'ODBA_1', 'ODBA_2', 'ODBA_3', 'ODBA_4', 'ODBA_5', 'ODBA_6', 'ODBA_7', 'ODBA_8', 'ODBA_9']].to_numpy()\n",
    "aux_combined_data = np.concatenate(aux_combined_data)\n",
    "\n",
    "# Check combined data shape and head\n",
    "print(aux_combined_data.shape)\n",
    "print(aux_combined_data[:10])\n",
    "\n",
    "# Print nan values in combined data\n",
    "print(f\"NaN values: {np.isnan(aux_combined_data).sum()}\")\n",
    "\n",
    "# Calculate mean and standard deviation\n",
    "mean_ODBA = np.nanmean(aux_combined_data)\n",
    "std_ODBA = np.nanstd(aux_combined_data)\n",
    "\n",
    "# Print mean and standard deviation\n",
    "print(f\"Mean: {mean_ODBA}\")\n",
    "print(f\"Standard deviation: {std_ODBA}\")\n",
    "\n",
    "# Calculate z-score for each ODBA value\n",
    "for i in range(10):\n",
    "    column_name = f'ODBA_{i}'\n",
    "    data_outlier_calc[column_name + '_zscore'] = (data_outlier_calc[column_name] - mean_ODBA) / std_ODBA\n",
    "\n",
    "# Print first 5 rows of the new dataframe\n",
    "print(data_outlier_calc.head())\n",
    "\n",
    "# Create new dataframe to filter outliers\n",
    "data_no_outliers = data_outlier_calc.copy()\n",
    "\n",
    "# Filter outliers by z-score outside of -3 and 3\n",
    "for i in range(10):\n",
    "    column_name = f'ODBA_{i}'\n",
    "    data_no_outliers = data_no_outliers.loc[data_no_outliers[column_name + '_zscore'].abs() <= 3]\n",
    "\n",
    "# Clean z-score columns\n",
    "data_no_outliers = data_no_outliers.drop(columns=['ODBA_0_zscore', 'ODBA_1_zscore', 'ODBA_2_zscore', 'ODBA_3_zscore', 'ODBA_4_zscore', 'ODBA_5_zscore', 'ODBA_6_zscore', 'ODBA_7_zscore', 'ODBA_8_zscore', 'ODBA_9_zscore'])\n",
    "\n",
    "# Print the shape of both dataframes\n",
    "print(f\"Original data shape: {data_raw.shape}\")\n",
    "print(f\"Data without outliers filtered by ODBA value: {data_no_outliers.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el analisis inicial realizado para datos por fila simple, fueron registrados con distintos puntos de colores de acuerdo a los valores medidos de _X_, _Y_ y _Z_ vs el _ODBA_. En este caso, como la cantidad de entrada es 40, no podemos realizar el mismo grafico. Lo que si podriamos es graficar los valores promedios medidos durante el segundo en particular."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2- Preparacion de datos\n",
    "\n",
    "Procedemos entonces con el siguiente paso: escalar los datos para que tengan valores entre -1 y 1, para darle de ingesta al modelo de red neuronal, cuyas capas de entrada reciben valores continuos entre esos valores, usando el objeto MinMaxScaler de la librer√≠a Scikit Learn.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scaled_data type: <class 'numpy.ndarray'>\n",
      "scaled_df type: <class 'pandas.core.frame.DataFrame'> scaled_df shape: (1171, 40)\n",
      "(1171, 41)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Create a MinMaxScaler object\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "# Scale the data\n",
    "scaled_data = scaler.fit_transform(data_no_outliers.select_dtypes(include='float'))\n",
    "\n",
    "print(f\"scaled_data type: {type(scaled_data)}\")\n",
    "\n",
    "# Convert the numpy array to a dataframe\n",
    "scaled_df = pd.DataFrame(scaled_data, columns=data_no_outliers.select_dtypes(include='float').columns)\n",
    "print(f\"scaled_df type: {type(scaled_df)} scaled_df shape: {scaled_df.shape}\")\n",
    "\n",
    "# Append Comportamiento column to scaled dataframe\n",
    "scaled_df['Comportamiento'] = data_no_outliers['Comportamiento'].values\n",
    "\n",
    "# Print the scaled dataframe\n",
    "print(scaled_df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez esten escalados los datos, separamos en los sets de entrenamiento y pruebas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (936, 41)\n",
      "Test data shape: (235, 41)\n"
     ]
    }
   ],
   "source": [
    "# Perform test-train split\n",
    "train_data, test_data = train_test_split(scaled_df, test_size=0.2, random_state=RANDOM_SEED)\n",
    "\n",
    "# Print the shapes of the train and test data\n",
    "print(\"Train data shape:\", train_data.shape)\n",
    "print(\"Test data shape:\", test_data.shape)\n",
    "\n",
    "# Prepare training and validation data for model.fit()\n",
    "X_train = train_data.drop(columns=['Comportamiento'])\n",
    "y_train = train_data['Comportamiento']\n",
    "X_test = test_data.drop(columns=['Comportamiento'])\n",
    "y_test = test_data['Comportamiento']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo ultimo que tenemos que hacer es codificar los valores de salida para mapearlos a una neurona de salida por cada categoria. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Convert the target variable to numerical labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos el modelo a generar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 40)                1640      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                820       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 7)                 77        \n",
      "=================================================================\n",
      "Total params: 2,747\n",
      "Trainable params: 2,747\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create new model with 40 columns as input, \"Comportamiento\" as cathegorical output, and 2 hidden layers with 20 and 10 neurons\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(40, input_shape=(40,), activation='relu'),\n",
    "    keras.layers.Dense(20, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='relu'),\n",
    "    keras.layers.Dense(units=7, activation='softmax')\n",
    "])\n",
    "    \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compilamos el modelo y lo entrenamos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "936/936 [==============================] - 1s 910us/step - loss: 1.3068 - accuracy: 0.4893\n",
      "Epoch 2/100\n",
      "936/936 [==============================] - 1s 972us/step - loss: 1.0519 - accuracy: 0.5609\n",
      "Epoch 3/100\n",
      "936/936 [==============================] - 1s 892us/step - loss: 0.9529 - accuracy: 0.6314\n",
      "Epoch 4/100\n",
      "936/936 [==============================] - 1s 919us/step - loss: 0.8870 - accuracy: 0.6720\n",
      "Epoch 5/100\n",
      "936/936 [==============================] - 1s 934us/step - loss: 0.8574 - accuracy: 0.6774\n",
      "Epoch 6/100\n",
      "936/936 [==============================] - 1s 936us/step - loss: 0.8315 - accuracy: 0.6902\n",
      "Epoch 7/100\n",
      "936/936 [==============================] - 1s 940us/step - loss: 0.8171 - accuracy: 0.6838\n",
      "Epoch 8/100\n",
      "936/936 [==============================] - 1s 911us/step - loss: 0.7862 - accuracy: 0.7019\n",
      "Epoch 9/100\n",
      "936/936 [==============================] - 1s 941us/step - loss: 0.7815 - accuracy: 0.7019\n",
      "Epoch 10/100\n",
      "936/936 [==============================] - 1s 944us/step - loss: 0.7727 - accuracy: 0.6987\n",
      "Epoch 11/100\n",
      "936/936 [==============================] - 1s 933us/step - loss: 0.7644 - accuracy: 0.7115\n",
      "Epoch 12/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.7463 - accuracy: 0.7105\n",
      "Epoch 13/100\n",
      "936/936 [==============================] - 1s 939us/step - loss: 0.7351 - accuracy: 0.7158\n",
      "Epoch 14/100\n",
      "936/936 [==============================] - 1s 982us/step - loss: 0.7228 - accuracy: 0.7169\n",
      "Epoch 15/100\n",
      "936/936 [==============================] - 1s 980us/step - loss: 0.7140 - accuracy: 0.7286\n",
      "Epoch 16/100\n",
      "936/936 [==============================] - 1s 976us/step - loss: 0.7087 - accuracy: 0.7158\n",
      "Epoch 17/100\n",
      "936/936 [==============================] - 1s 922us/step - loss: 0.6936 - accuracy: 0.7212\n",
      "Epoch 18/100\n",
      "936/936 [==============================] - 1s 917us/step - loss: 0.6902 - accuracy: 0.7222\n",
      "Epoch 19/100\n",
      "936/936 [==============================] - 1s 934us/step - loss: 0.6781 - accuracy: 0.7468\n",
      "Epoch 20/100\n",
      "936/936 [==============================] - 1s 946us/step - loss: 0.6728 - accuracy: 0.7340\n",
      "Epoch 21/100\n",
      "936/936 [==============================] - 1s 958us/step - loss: 0.6634 - accuracy: 0.7265\n",
      "Epoch 22/100\n",
      "936/936 [==============================] - 1s 930us/step - loss: 0.6629 - accuracy: 0.7479\n",
      "Epoch 23/100\n",
      "936/936 [==============================] - 1s 982us/step - loss: 0.6531 - accuracy: 0.7468\n",
      "Epoch 24/100\n",
      "936/936 [==============================] - 1s 954us/step - loss: 0.6353 - accuracy: 0.7596\n",
      "Epoch 25/100\n",
      "936/936 [==============================] - 1s 919us/step - loss: 0.6380 - accuracy: 0.7457\n",
      "Epoch 26/100\n",
      "936/936 [==============================] - 1s 909us/step - loss: 0.6272 - accuracy: 0.7564\n",
      "Epoch 27/100\n",
      "936/936 [==============================] - 1s 924us/step - loss: 0.6253 - accuracy: 0.7543\n",
      "Epoch 28/100\n",
      "936/936 [==============================] - 1s 956us/step - loss: 0.6109 - accuracy: 0.7639\n",
      "Epoch 29/100\n",
      "936/936 [==============================] - 1s 894us/step - loss: 0.5993 - accuracy: 0.7682\n",
      "Epoch 30/100\n",
      "936/936 [==============================] - 1s 896us/step - loss: 0.5996 - accuracy: 0.7628\n",
      "Epoch 31/100\n",
      "936/936 [==============================] - 1s 899us/step - loss: 0.5855 - accuracy: 0.7767\n",
      "Epoch 32/100\n",
      "936/936 [==============================] - 1s 916us/step - loss: 0.5833 - accuracy: 0.7724\n",
      "Epoch 33/100\n",
      "936/936 [==============================] - 1s 915us/step - loss: 0.5786 - accuracy: 0.7831\n",
      "Epoch 34/100\n",
      "936/936 [==============================] - 1s 947us/step - loss: 0.5566 - accuracy: 0.7842\n",
      "Epoch 35/100\n",
      "936/936 [==============================] - 1s 957us/step - loss: 0.5789 - accuracy: 0.7767\n",
      "Epoch 36/100\n",
      "936/936 [==============================] - 1s 972us/step - loss: 0.5582 - accuracy: 0.7756\n",
      "Epoch 37/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.5454 - accuracy: 0.7842\n",
      "Epoch 38/100\n",
      "936/936 [==============================] - 1s 942us/step - loss: 0.5399 - accuracy: 0.7949\n",
      "Epoch 39/100\n",
      "936/936 [==============================] - 1s 896us/step - loss: 0.5227 - accuracy: 0.8045\n",
      "Epoch 40/100\n",
      "936/936 [==============================] - 1s 885us/step - loss: 0.5360 - accuracy: 0.7927\n",
      "Epoch 41/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.5152 - accuracy: 0.8066\n",
      "Epoch 42/100\n",
      "936/936 [==============================] - 1s 999us/step - loss: 0.5073 - accuracy: 0.8077\n",
      "Epoch 43/100\n",
      "936/936 [==============================] - 1s 909us/step - loss: 0.5022 - accuracy: 0.7991\n",
      "Epoch 44/100\n",
      "936/936 [==============================] - 1s 990us/step - loss: 0.5172 - accuracy: 0.7970\n",
      "Epoch 45/100\n",
      "936/936 [==============================] - 1s 999us/step - loss: 0.5018 - accuracy: 0.8024\n",
      "Epoch 46/100\n",
      "936/936 [==============================] - 1s 950us/step - loss: 0.4765 - accuracy: 0.8141\n",
      "Epoch 47/100\n",
      "936/936 [==============================] - 1s 1000us/step - loss: 0.4793 - accuracy: 0.8259\n",
      "Epoch 48/100\n",
      "936/936 [==============================] - 1s 925us/step - loss: 0.4861 - accuracy: 0.8226\n",
      "Epoch 49/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.4708 - accuracy: 0.8184\n",
      "Epoch 50/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.4719 - accuracy: 0.8269\n",
      "Epoch 51/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.4552 - accuracy: 0.8397\n",
      "Epoch 52/100\n",
      "936/936 [==============================] - 1s 933us/step - loss: 0.4530 - accuracy: 0.8365\n",
      "Epoch 53/100\n",
      "936/936 [==============================] - 1s 939us/step - loss: 0.4529 - accuracy: 0.8280\n",
      "Epoch 54/100\n",
      "936/936 [==============================] - 1s 940us/step - loss: 0.4388 - accuracy: 0.8365\n",
      "Epoch 55/100\n",
      "936/936 [==============================] - 1s 965us/step - loss: 0.4291 - accuracy: 0.8429\n",
      "Epoch 56/100\n",
      "936/936 [==============================] - 1s 941us/step - loss: 0.4460 - accuracy: 0.8237\n",
      "Epoch 57/100\n",
      "936/936 [==============================] - 1s 988us/step - loss: 0.4255 - accuracy: 0.8462\n",
      "Epoch 58/100\n",
      "936/936 [==============================] - 1s 979us/step - loss: 0.4130 - accuracy: 0.8472\n",
      "Epoch 59/100\n",
      "936/936 [==============================] - 1s 974us/step - loss: 0.4149 - accuracy: 0.8526\n",
      "Epoch 60/100\n",
      "936/936 [==============================] - 1s 972us/step - loss: 0.4092 - accuracy: 0.8462\n",
      "Epoch 61/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.4017 - accuracy: 0.8547\n",
      "Epoch 62/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.4251 - accuracy: 0.8547\n",
      "Epoch 63/100\n",
      "936/936 [==============================] - 1s 969us/step - loss: 0.4109 - accuracy: 0.8536\n",
      "Epoch 64/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.3868 - accuracy: 0.8611\n",
      "Epoch 65/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.3818 - accuracy: 0.8526\n",
      "Epoch 66/100\n",
      "936/936 [==============================] - 1s 991us/step - loss: 0.3696 - accuracy: 0.8590\n",
      "Epoch 67/100\n",
      "936/936 [==============================] - 1s 994us/step - loss: 0.3868 - accuracy: 0.8579\n",
      "Epoch 68/100\n",
      "936/936 [==============================] - 1s 984us/step - loss: 0.3723 - accuracy: 0.8558\n",
      "Epoch 69/100\n",
      "936/936 [==============================] - 1s 959us/step - loss: 0.3666 - accuracy: 0.8707\n",
      "Epoch 70/100\n",
      "936/936 [==============================] - 1s 935us/step - loss: 0.3585 - accuracy: 0.8654\n",
      "Epoch 71/100\n",
      "936/936 [==============================] - 1s 994us/step - loss: 0.3720 - accuracy: 0.8643\n",
      "Epoch 72/100\n",
      "936/936 [==============================] - 1s 996us/step - loss: 0.3580 - accuracy: 0.8590\n",
      "Epoch 73/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.3443 - accuracy: 0.8707\n",
      "Epoch 74/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.3559 - accuracy: 0.8632\n",
      "Epoch 75/100\n",
      "936/936 [==============================] - 1s 992us/step - loss: 0.3346 - accuracy: 0.8761\n",
      "Epoch 76/100\n",
      "936/936 [==============================] - 1s 930us/step - loss: 0.3347 - accuracy: 0.8707\n",
      "Epoch 77/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.3417 - accuracy: 0.8771\n",
      "Epoch 78/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.3330 - accuracy: 0.8729\n",
      "Epoch 79/100\n",
      "936/936 [==============================] - 1s 966us/step - loss: 0.3138 - accuracy: 0.8889\n",
      "Epoch 80/100\n",
      "936/936 [==============================] - 1s 924us/step - loss: 0.3349 - accuracy: 0.8814\n",
      "Epoch 81/100\n",
      "936/936 [==============================] - 1s 987us/step - loss: 0.3213 - accuracy: 0.8825\n",
      "Epoch 82/100\n",
      "936/936 [==============================] - 1s 941us/step - loss: 0.3177 - accuracy: 0.8814\n",
      "Epoch 83/100\n",
      "936/936 [==============================] - 1s 944us/step - loss: 0.2973 - accuracy: 0.8921\n",
      "Epoch 84/100\n",
      "936/936 [==============================] - 1s 930us/step - loss: 0.3292 - accuracy: 0.8675\n",
      "Epoch 85/100\n",
      "936/936 [==============================] - 1s 979us/step - loss: 0.3040 - accuracy: 0.8953\n",
      "Epoch 86/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.2870 - accuracy: 0.8932\n",
      "Epoch 87/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.2924 - accuracy: 0.9017\n",
      "Epoch 88/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.2884 - accuracy: 0.9006\n",
      "Epoch 89/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.2848 - accuracy: 0.8974\n",
      "Epoch 90/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.2737 - accuracy: 0.9049\n",
      "Epoch 91/100\n",
      "936/936 [==============================] - 1s 964us/step - loss: 0.2925 - accuracy: 0.8932\n",
      "Epoch 92/100\n",
      "936/936 [==============================] - 1s 941us/step - loss: 0.2950 - accuracy: 0.8910\n",
      "Epoch 93/100\n",
      "936/936 [==============================] - 1s 999us/step - loss: 0.2699 - accuracy: 0.9092\n",
      "Epoch 94/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.2703 - accuracy: 0.9017\n",
      "Epoch 95/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.2618 - accuracy: 0.9092\n",
      "Epoch 96/100\n",
      "936/936 [==============================] - 1s 945us/step - loss: 0.2637 - accuracy: 0.9017\n",
      "Epoch 97/100\n",
      "936/936 [==============================] - 1s 966us/step - loss: 0.2933 - accuracy: 0.8942\n",
      "Epoch 98/100\n",
      "936/936 [==============================] - 1s 931us/step - loss: 0.2741 - accuracy: 0.9081\n",
      "Epoch 99/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.2416 - accuracy: 0.9071\n",
      "Epoch 100/100\n",
      "936/936 [==============================] - 1s 1ms/step - loss: 0.2696 - accuracy: 0.9038\n"
     ]
    }
   ],
   "source": [
    "# Compile and fit the model with the numerical labels\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "training_history = model.fit(X_train, y_train_encoded, epochs=100, batch_size=1, verbose=1, use_multiprocessing=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardamos el modelo para referencia a futuro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "# Save model with the name \"model_\" + the current date and time as h5 file\n",
    "model.save(\"../models/model_data_per_second_\" + datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\") + \".h5\")\n",
    "\n",
    "# model.save(\"model_data_per_second_202402020202.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Training checkpoint! \n",
    "Arriba se guardo el modelo recientemente entrenado, salido del horno... Desde aca en adelante podemos cargarlo para revisarlo mejor. (o no, si ya estaba cargado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-02 20:03:46.692056: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2024-02-02 20:03:46.692092: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2024-02-02 20:03:46.692116: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (7681f9de3c06): /proc/driver/nvidia/version does not exist\n",
      "2024-02-02 20:03:46.694453: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "# model = keras.models.load_model('../models/model_data_per_second_202402020202.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 1ms/step - loss: 3.1508 - accuracy: 0.6170\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.1508383750915527, 0.6170212626457214]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Convert the target variable to numerical labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_test_encoded = label_encoder.fit_transform(y_test)\n",
    "\n",
    "\n",
    "# Evaluate the model with the one-hot encoded target variable\n",
    "model.evaluate(X_test, y_test_encoded)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que esta interpretacion base no se comporta del todo bien que digamos, un 60% de accuracy nada mas con el set de prueba. Igual podemos ver que capaz un problema que no corregimos fue la desproporcionalidad de muestras de cada evento en la celda superior. Podriamos emparejar los numeros de muestra para ver que tan bien se comporta esta red base. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
